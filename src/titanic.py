# -*- coding: utf-8 -*-
"""intento_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jQBu1Qih7ZUGuT5nmy3vu-lPbannSPY7

# Librerias
"""


import pandas as pd
import numpy as np

from sklearn.pipeline import Pipeline

from sklearn.metrics import accuracy_score, roc_auc_score
from sklearn.model_selection import train_test_split
from sklearn.base import BaseEstimator, TransformerMixin

from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LogisticRegression
from xgboost.sklearn import XGBClassifier

# aqui si solo vamos a preparar los datos que va a recibir el pipeline
def pre_data( df ) :
  df.replace('?',np.nan,inplace=True)
  df['age'] = df['age'].astype(float)
  df['fare'] = df['fare'].astype(float)

  df['num_dest'] = df['home.dest'].astype(str).apply(lambda x : len( x.split('/')))
  df.loc[df['home.dest'].isnull(),'num_dest'] = 0
  
  df['if_body'] = df.body.notnull() * 1
  
  return df

# en esta clase vamos a imputar los valores nulos de las variables continuas    
class NumericalImputer(BaseEstimator, TransformerMixin):
    
    def __init__(self, variables=None):
        if not isinstance(variables, list):
            self.variables = [variables]
        else:
            self.variables = variables
    
    ### Crea el directio de iputacion es decir sobre el df que se le este pasando va a calular la media
    def fit(self, X, y=None):
        self.median_dict_ = {}
        for var in self.variables:
            self.median_dict_[var] = X[var].median()
        return self

    #### Aqui ahora si imputa los valores obtenidos en el aprendizaje anterior     
    def transform(self, X):
        X = X.copy()
        for var in self.variables:
            X[var] = X[var].fillna(self.median_dict_[var])
        return X

## Podria ser un fillna con 'misiing para las categoricas como hace el onehot, solo es una columna m√°s
class CategoricalImputer(BaseEstimator, TransformerMixin):
    
    def __init__(self, variables=None):
        if not isinstance(variables, list):
            self.variables = [variables]
        else:
            self.variables = variables
    
    def fit(self, X, y=None):
        return self
    
    def transform(self, X):
        X = X.copy()
        for var in self.variables:
            X[var] = X[var].fillna('Missing')
        return X

#  discrate_features =['sex','cabin','embarked'] Este parametro lo recibe dentro del pipeline
#  X_dum = df[discrate_features]

## Esta Parte es la que va en la transformacion de la consutruccion
#  X_dum = pd.concat([X_dum, pd.get_dummies(X_dum[discrate_features], drop_first=True)], 1)
#  X_dum.drop(columns = discrate_features, inplace=True)


"""class OneHotEncoder(BaseEstimator, TransformerMixin):
    
    def __init__(self, variables=None):
        if not isinstance(variables, list):
            self.variables = [variables]
        else:
            self.variables = variables

    ### Esta aprendiendo el HotEncoder   
    def fit(self, X, y=None):
        self.dummies = pd.get_dummies(X[self.variables], drop_first=True).columns
        return self

    ## Transforma los datos
    def transform(self, X):
        X = X.copy()
        X = pd.concat([X, pd.get_dummies(X[self.variables], drop_first=True)], 1)
        X.drop(self.variables, 1, inplace=True)
        
        # En caso de tener nuevos valores en las columnas
        # Adding missing dummies, if any
        missing_dummies = [var for var in self.dummies if var not in X.columns]
        if len(missing_dummies) != 0:
            for col in missing_dummies:
                X[col] = 0
        
        return X """

TARGET = 'survived'
FEATURES = ['pclass','sex','age','sibsp','parch','fare','cabin','embarked']
NUMERICAL_VARS = ['pclass','age','sibsp','parch','fare']
CATEGORICAL_VARS = ['sex','cabin','embarked']

SEED_MODEL = 404


NUMERICAL_VARS_WITH_NA = ['age','fare']
CATEGORICAL_VARS_WITH_NA = ['cabin','embarked']
NUMERICAL_NA_NOT_ALLOWED = [var for var in NUMERICAL_VARS if var not in NUMERICAL_VARS_WITH_NA]
CATEGORICAL_NA_NOT_ALLOWED = [var for var in CATEGORICAL_VARS if var not in CATEGORICAL_VARS_WITH_NA]

intento_1 = Pipeline([ 
                          ('categorical_imputer', CategoricalImputer(variables=CATEGORICAL_VARS_WITH_NA)),
                          ('median_imputation', NumericalImputer(variables=NUMERICAL_VARS_WITH_NA)),
                         # ('dummy_vars', OneHotEncoder(variables=CATEGORICAL_VARS)),
                         ('scaling', MinMaxScaler()),
                         ('log_reg', LogisticRegression(C=0.0005, class_weight='balanced', random_state=SEED_MODEL)),
                         # ('xgb',XGBClassifier(objective='binary:logistic', use_label_encoder=False)),
                              ])

df = pd.read_csv('/content/titanic.csv')
df = pre_data(df)
df = df[['survived','pclass','sex','age','sibsp','parch','fare','cabin','embarked']]

X_train, X_test, y_train, y_test = train_test_split(
                                                        df.drop(TARGET, axis=1),
                                                        df[TARGET],
                                                        test_size=0.2,
                                                        random_state=404
                                                   )

intento_1.fit(X_train, y_train);

class_pred = intento_1.predict(X_test)
proba_pred = intento_1.predict_proba(X_test)[:,1]
print('test roc-auc : {}'.format(roc_auc_score(y_test, proba_pred)))
print('test accuracy: {}'.format(accuracy_score(y_test, class_pred)))



